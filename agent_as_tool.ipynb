{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCYQs9z7gF2xFWZj0hKa3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubaahmedkhan/AgenticAI-Toolkit-/blob/main/agent_as_tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMLOPoHpscp8",
        "outputId": "e9914693-73af-463f-f717-47982dc467fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.3 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.6/734.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install  -qU openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "sZ0HkT5ztJqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "LPUayXpstOt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True\n",
        ")"
      ],
      "metadata": {
        "id": "xZ8SC0-IuNfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents.tool import function_tool"
      ],
      "metadata": {
        "id": "DO7XlEJKuXOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool(\"get_weather\")\n",
        "def get_weather(location: str, unit: str = \"C\") -> str:\n",
        "  \"\"\"\n",
        "  You are a Web Development Assistant. You only respond to queries related to web development, including front-end and back-end technologies,\n",
        "  frameworks (like HTML, CSS, JavaScript, React, Node.js, etc.), APIs, databases, hosting, and deployment. You must not respond to questions\n",
        "   outside the scope of web development. For unrelated queries, politely inform the user that your role is limited to web development assistance only.\n",
        "  \"\"\"\n",
        "  # Example logic\n",
        "  return f\"The weather in {location} is 22 degrees {unit}.\"\n"
      ],
      "metadata": {
        "id": "uNTZpBYVvhIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool(\"piaic_student_finder\")\n",
        "def student_finder(student_roll: int) -> str:\n",
        "  \"\"\"\n",
        "  find the PIAIC student based on the roll number\n",
        "  \"\"\"\n",
        "  data = {1: \"Qasim\",\n",
        "          2: \"Sir Zia\",\n",
        "          3: \"Daniyal\"}\n",
        "\n",
        "  return data.get(student_roll, \"Not Found\")"
      ],
      "metadata": {
        "id": "smUaKiscvJGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@function_tool(\"get_weather\")\n",
        "def get_weather(location: str, unit: str = \"C\") -> str:\n",
        "  \"\"\"\n",
        "  Fetch the weather for a given location, returning a short description.\n",
        "  \"\"\"\n",
        "  # Example logic\n",
        "  return f\"The weather in {location} is 22 degrees {unit}.\"\n"
      ],
      "metadata": {
        "id": "03wzAuYoveFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "from agents import Agent, Runner\n",
        "\n",
        "web_development_expert:Agent = Agent(\n",
        "        name=\"Web Development Agent\",\n",
        "        instructions=\"You are a Web Development Assistant. You only respond to queries related to web development,\",\n",
        "        model=model,\n",
        "        handoff_description=\"Web development expert\"\n",
        "    )\n",
        "\n",
        "mobile_development_expert:Agent = Agent(\n",
        "        name=\"mobile Development Agent\",\n",
        "        instructions=\"You are a mobile Development Assistant. You only respond to queries related to mobile development,\",\n",
        "        model=model,\n",
        "        handoff_description=\"mobile development expert\"\n",
        "    )\n",
        "Devops_expert:Agent = Agent(\n",
        "        name=\"Devops Agent\",\n",
        "        instructions=\"You are a Devops Assistant. You only respond to queries related to Devops,\",\n",
        "        model=model,\n",
        "        handoff_description=\"Devops expert\"\n",
        "    )\n",
        "Openai_agent:Agent = Agent(\n",
        "        name=\"OpenAI Agent\",\n",
        "        instructions=\"You are a OpenAI Assistant. You only respond to queries related to OpenAI,\",\n",
        "        model=model,\n",
        "        handoff_description=\"OpenAI expert\"\n",
        "    )\n",
        "Agentic_AI_expert:Agent = Agent(\n",
        "        name=\"AI Development Agent\",\n",
        "        instructions=\"\"\"You are an AI Development Assistant. You only respond to queries related to AI development. You have access to two tools to assist with your tasks Agentic_AI –\n",
        "                     for handling questions related to autonomous or agent-based AI systems\n",
        "\n",
        "                     DevOps: for managing AI deployment, CI/CD, and infrastructure-related tasks\n",
        "\n",
        "\n",
        "                     Agentic_AI: for handling questions related to autonomous or agent-based AI systems\n",
        "                     Use these tools when appropriate to provide accurate and efficient support\n",
        "                    \"\"\",\n",
        "        tools=[\n",
        "        Devops_expert.as_tool(\n",
        "            tool_name=\"Devops\",\n",
        "            tool_description=\"provide detail answer related to agentic ai related queries\",\n",
        "        ),\n",
        "        Openai_agent.as_tool(\n",
        "            tool_name=\"open AI expert\",\n",
        "            tool_description=\"provide detail answer related to agentic ai related queries\",\n",
        "        ),\n",
        "\n",
        "    ],\n",
        "        model=model,\n",
        "        handoff_description=\"AI development expert\"\n",
        "    )\n",
        "\n",
        "triage_agent:Agent = Agent(\n",
        "        name=\"Triage agent\",\n",
        "        instructions=\"Redirect all questions related to web development, mobile development, or Agentic AI to their respective agents: web_development_expert, mobile_development_expert, and Agentic_AI_expert..\",\n",
        "        model=model,\n",
        "        handoffs=[web_development_expert,mobile_development_expert,Agentic_AI_expert]\n",
        "    )\n",
        "\n",
        "result = await Runner.run(triage_agent, \"describe devops.\")\n",
        "print(result.final_output)\n",
        "print(result.last_agent)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdaNMOGwvQ9b",
        "outputId": "c8f9d53f-080d-40d8-ef95-276c9751d191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DevOps is a set of practices, tools, and a cultural philosophy that automates and integrates the processes between software development and IT teams.  It aims to shorten the systems development life cycle and provide continuous delivery with high software quality.  This is achieved through a collaborative approach that emphasizes communication, shared responsibility, and automation.  Key aspects include continuous integration, continuous delivery/continuous deployment (CI/CD), infrastructure as code, and monitoring.\n",
            "\n",
            "Agent(name='Triage agent', instructions='Redirect all questions related to web development, mobile development, or Agentic AI to their respective agents: web_development_expert, mobile_development_expert, and Agentic_AI_expert..', prompt=None, handoff_description=None, handoffs=[Agent(name='Web Development Agent', instructions='You are a Web Development Assistant. You only respond to queries related to web development,', prompt=None, handoff_description='Web development expert', handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7ad3c62a2d90>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='mobile Development Agent', instructions='You are a mobile Development Assistant. You only respond to queries related to mobile development,', prompt=None, handoff_description='mobile development expert', handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7ad3c62a2d90>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), Agent(name='AI Development Agent', instructions='You are an AI Development Assistant. You only respond to queries related to AI development. You have access to two tools to assist with your tasks Agentic_AI –\\n                     for handling questions related to autonomous or agent-based AI systems\\n\\n                     DevOps: for managing AI deployment, CI/CD, and infrastructure-related tasks\\n\\n\\n                     Agentic_AI: for handling questions related to autonomous or agent-based AI systems\\n                     Use these tools when appropriate to provide accurate and efficient support\\n                    ', prompt=None, handoff_description='AI development expert', handoffs=[], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7ad3c62a2d90>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[FunctionTool(name='Devops', description='provide detail answer related to agentic ai related queries', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'Devops_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ad3c5db91c0>, strict_json_schema=True, is_enabled=True), FunctionTool(name='open AI expert', description='provide detail answer related to agentic ai related queries', params_json_schema={'properties': {'input': {'title': 'Input', 'type': 'string'}}, 'required': ['input'], 'title': 'open AI expert_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7ad3c5cac040>, strict_json_schema=True, is_enabled=True)], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)], model=<agents.models.openai_chatcompletions.OpenAIChatCompletionsModel object at 0x7ad3c62a2d90>, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n"
          ]
        }
      ]
    }
  ]
}